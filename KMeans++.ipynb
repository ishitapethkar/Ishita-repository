{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Data\"\n",
    "files = [\n",
    "    \"docword.kos.txt\",\n",
    "    \"docword.nips.txt\",\n",
    "    \"docword.enron.txt\",\n",
    "    ]\n",
    "max_k = 25\n",
    "k_iters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npify(indices:set|list,\n",
    "          arr_len:int):\n",
    "    arr = np.zeros(arr_len)\n",
    "    for index in indices:\n",
    "        arr[index - 1] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def setify(arr):\n",
    "    threshold = min(0.4, 0.75 * np.max(arr))\n",
    "    indices = []\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] - threshold >= -1e-3:\n",
    "            indices.append(i)\n",
    "    return set(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jac_dist(v1:set,\n",
    "             v2:set):    \n",
    "    union = len(v1.union(v2))\n",
    "    intersection = len(v1.intersection(v2))\n",
    "    \n",
    "    if union == 0:\n",
    "        return 1\n",
    "    \n",
    "    jacc_dist = (union - intersection) / union\n",
    "    return jacc_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_inertia(data,\n",
    "                 cluster_labels,\n",
    "                 centroids):\n",
    "    inertia = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        inertia += jac_dist(\n",
    "            data[i],\n",
    "            centroids[cluster_labels[i]]\n",
    "            )\n",
    "    \n",
    "    return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_kmeans(data:list,\n",
    "                  k:int,\n",
    "                  dim:int,\n",
    "                  max_iter=100,\n",
    "                  past_centroids:list=None,\n",
    "                  past_labels:list=None):\n",
    "    \"\"\"\n",
    "    Custom K-Means implementation with a Jaccard Similarity Measure.\n",
    "\n",
    "    Args:\n",
    "        data: \n",
    "        k: The desired number of clusters.\n",
    "        max_iter: Maximum number of iterations (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            cluster_labels: An array of cluster labels for each data point.\n",
    "            centroids: The final centroids (cluster centers) after convergence.\n",
    "            intertia: The inertia for the final centroids and clusters\n",
    "    \"\"\"\n",
    "\n",
    "    if k == 2:\n",
    "        # Initialize the first centroid randomly\n",
    "        rnd = np.random.choice(a=len(data),\n",
    "                                size=1,\n",
    "                                replace=False)\n",
    "        centroids = []\n",
    "        centroids.append(data[rnd[0]])\n",
    "        \n",
    "        cluster_labels = [0] * len(data)\n",
    "    else:\n",
    "        centroids = past_centroids\n",
    "        cluster_labels = past_labels\n",
    "    \n",
    "    # Add next centroid as the one that is furthest from first centroid\n",
    "    furthest_pt = data[0]\n",
    "    max_dist = 0\n",
    "    for i in range(len(data)):\n",
    "        pt = data[i]\n",
    "        c = centroids[cluster_labels[i]]\n",
    "        \n",
    "        if jac_dist(c, pt) > max_dist:\n",
    "            furthest_pt = pt\n",
    "            max_dist = jac_dist(c, pt)\n",
    "    \n",
    "    centroids.append(furthest_pt)\n",
    "        \n",
    "    # Re-assign cluster labels\n",
    "    for i in range(len(data)):\n",
    "        new_c = 0\n",
    "        for j in range(len(centroids)):\n",
    "            if jac_dist(data[i], centroids[new_c]) \\\n",
    "                > jac_dist(data[i], centroids[j]):\n",
    "                new_c = j\n",
    "        \n",
    "        cluster_labels[i] = new_c\n",
    "\n",
    "    # Try to Converge via kmeans\n",
    "    for _ in range(max_iter):\n",
    "        old_centroids = centroids.copy()\n",
    "        old_labels = cluster_labels\n",
    "        \n",
    "        # Calculate Mean of points\n",
    "        pts_per_cl = [0] * len(centroids)\n",
    "        sum_per_cl = [np.zeros(dim)] * len(centroids)\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            c = old_labels[i]\n",
    "            pts_per_cl[c] += 1\n",
    "            sum_per_cl[c] += npify(data[i], dim)\n",
    "        \n",
    "        new_centroids = []\n",
    "        for i in range(len(centroids)):\n",
    "            new_centroids.append(setify(sum_per_cl[i] / pts_per_cl[i]))\n",
    "        \n",
    "        # Assign data points to closest centroids\n",
    "        new_labels = []\n",
    "        for i in range(len(data)):\n",
    "            c = 0\n",
    "            dist = jac_dist(data[i], centroids[c])\n",
    "            for j in range(len(centroids)):\n",
    "                if  dist > jac_dist(data[i], centroids[j]):\n",
    "                    c = j\n",
    "                    dist = jac_dist(data[i], centroids[c])\n",
    "            \n",
    "            new_labels.append(c)\n",
    "        \n",
    "        # Stop if new clusters increase inertia\n",
    "        if calc_inertia(data, cluster_labels=old_labels,\n",
    "                centroids=old_centroids) < \\\n",
    "            calc_inertia(data, cluster_labels=new_labels,\n",
    "                centroids=new_centroids):\n",
    "            cluster_labels = old_labels\n",
    "            centroids = old_centroids\n",
    "            break\n",
    "        else:\n",
    "            cluster_labels = new_labels\n",
    "            centroids = new_centroids\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.all(np.array([jac_dist(c, oc)\n",
    "                            for c in new_centroids\n",
    "                            for oc in old_centroids]) < 1e-3):\n",
    "            break\n",
    "                \n",
    "    # Calculate Inertia            \n",
    "    inertia = calc_inertia(\n",
    "                data=data,\n",
    "                cluster_labels=cluster_labels,\n",
    "                centroids=centroids\n",
    "                )\n",
    "\n",
    "    return cluster_labels, centroids, inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_pipeline(file:str,\n",
    "                    max_k:int,\n",
    "                    k_iters:int):\n",
    "    \n",
    "    source = open(f'{file_path}/{file}', 'r')\n",
    "    D = int(next(source).strip())\n",
    "    W = int(next(source).strip())\n",
    "    NNZ = int(next(source).strip())\n",
    "    data = []\n",
    "\n",
    "    tmp = None\n",
    "    for line in source:\n",
    "        d, w, _ = list(map(int, line.strip().split()))\n",
    "        if d > len(data):\n",
    "            if tmp is not None:\n",
    "                data.append(set(tmp))\n",
    "            tmp = [w]\n",
    "        else:\n",
    "            tmp.append(w)\n",
    "    data.append(set(tmp))\n",
    "\n",
    "    # Sanity Check\n",
    "    read_words = sum([len(doc) for doc in data])\n",
    "    if read_words != NNZ:\n",
    "        return \"Failure: Data Read Improperly\"\n",
    "    \n",
    "    file_name = file.split('.')[1].upper()\n",
    "    \n",
    "    widgets = [f'Clustering on {file_name}: ', progressbar.Percentage(), ' | ',\n",
    "            progressbar.Timer(), ' | (', progressbar.ETA(), ') ']\n",
    "    bar = progressbar.ProgressBar(\n",
    "        maxval=(max_k - 1),\n",
    "        widgets=widgets)\\\n",
    "            .start()\n",
    "    \n",
    "    k_inertia = []\n",
    "    past_centroids = None\n",
    "    past_labels = None\n",
    "\n",
    "    for k in range(2, max_k + 1):\n",
    "        min_inertia = 10 ** 6\n",
    "        \n",
    "        if k == 2:\n",
    "            for _ in range(k_iters):\n",
    "                cluster_labels, centroids, inertia = \\\n",
    "                    custom_kmeans(\n",
    "                        data=data,\n",
    "                        k=k,\n",
    "                        dim=W,\n",
    "                        past_centroids=past_centroids,\n",
    "                        past_labels=past_labels\n",
    "                        )\n",
    "\n",
    "                if min_inertia > inertia:\n",
    "                    min_inertia = inertia\n",
    "                    min_centroids = centroids\n",
    "                    min_labels = cluster_labels\n",
    "        else:\n",
    "            cluster_labels, centroids, inertia = \\\n",
    "                custom_kmeans(\n",
    "                    data=data,\n",
    "                    k=k,\n",
    "                    dim=W,\n",
    "                    past_centroids=past_centroids,\n",
    "                    past_labels=past_labels\n",
    "                    )\n",
    "\n",
    "            min_inertia = inertia\n",
    "            min_centroids = centroids\n",
    "            min_labels = cluster_labels\n",
    "        \n",
    "        past_centroids = min_centroids\n",
    "        past_labels = min_labels\n",
    "        k_inertia.append(min_inertia)\n",
    "        bar.update(k - 2 + 1)\n",
    "\n",
    "    print(f'Sparsity of List on {file_name}: {NNZ / (D * W) * 100:.3f} %')\n",
    "    print(f'Size of List on {file_name}: {sys.getsizeof(data)} bytes')\n",
    "    print()\n",
    "    \n",
    "    return k_inertia            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering on KOS: 100% | Elapsed Time: 0:00:15 | (ETA:  0:00:00)              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of List on KOS: 1.491 %\n",
      "Size of List on KOS: 29336 bytes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering on NIPS: 100% | Elapsed Time: 0:00:40 | (ETA:  0:00:00)             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of List on NIPS: 4.006 %\n",
      "Size of List on NIPS: 12728 bytes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clustering on ENRON: 100% | Elapsed Time: 0:02:33 | (ETA:  0:00:00)            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of List on ENRON: 0.331 %\n",
      "Size of List on ENRON: 351064 bytes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    k_inertia = kmeans_pipeline(\n",
    "                    file=file,\n",
    "                    max_k=max_k,\n",
    "                    k_iters=k_iters)\n",
    "    \n",
    "    file_name = file.split('.')[1].upper()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(list(range(2, max_k + 1)),\n",
    "             k_inertia,\n",
    "             marker='o', \n",
    "             linestyle='-')\n",
    "    plt.title(f'Clustering on {file_name}')\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Inertia (Jaccard Similarity)')\n",
    "    plt.ylim([max(min(k_inertia) - 0.01 * max(k_inertia), 0), 1.01 * max(k_inertia)])\n",
    "    plt.savefig(f'Output/KM++ - SR/{file_name}.png')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
